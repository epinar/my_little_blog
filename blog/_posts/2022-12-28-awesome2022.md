---
layout: post
title: Tab cleanup day - Awesome 2022
categories: [research,CVPR,ECCV,Neurips]
comments: true
---


It was such a year, 2022! I was in the second year of my Ph.D, life going back to normal, attended to my first conference, published three papers, did an in-person internship in the U.S., partially managed to accomplish my personal resolutions. 

There are different types of blog-posts, from purely technical ones to rather survey-like posts. In the past, I did some from all, like revieweing a paper, or focusing on a task only, or even implementing and talking in detail about a paper. But I guess now, this is a new type of post which I'm coming up with the second edition, "tab cleanup day" :P This is just a very personal post with opinions on AI, placing my very personal self in-between the AI research. It personally helps me to flush - sort of. I first thought about consulting to ChatGPT to fix my grammar mistakes in this post, but then decided not to, as I have my own style and don't want to produce a generic text :P So I even keep my grammar mistakes along with my identity.

In fact, this time, it was not a tab-cleanup day, instead, it was a couple of days where I categorised all the papers I've collected in my tabs into concepts, ending up reading some papers fully and some partially, to try to decide on what to work on next on my third year. The issue is, research is progressing exponentially and last month I have been thinking on some ideas, and already came across to a couple of them already appearing in arxiv in December. Struggling with this reality, I somehow aim to sort topics and technical developments into their importance (from my point of view and only what I think is interesting). 

Here are some headlines and a curated list of papers from 2022, you can also check on github directly [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

## Diffusion models 
#### Theoretical background, VAE
Anything on score-based models, Neurips papers, ELBO, and its variations, different optimization schemes, what does it learn, how to improve capacity
- Elucidating design space [Neurips](https://github.com/NVlabs/edm) 
- Yang Song [blogpost score models](https://yang-song.net/blog/2021/score/) 
- VAE [booklet](https://arxiv.org/pdf/1906.02691.pdf) 
- [Understanding AE blog](https://towardsdatascience.com/understanding-autoencoders-with-an-example-a-step-by-step-tutorial-a79d2ea2945e) 
- [VAE colab](https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb)
- [VAE colab2](https://colab.research.google.com/github/lucmos/DLAI-s2-2020-tutorials/blob/master/08/8_Variational_Autoencoders_(VAEs).ipynb)
- [cheatsheet](https://www.linkedin.com/feed/update/activity:6985855403095924736)
- [unified perspective](https://calvinyluo.com/2022/08/26/diffusion-tutorial.html) 
- [maths - ai summer](https://theaisummer.com/diffusion-models/)

#### Applications in 2D downstream tasks, SD surgery
Object detection, segmentation, text-to-image, image-to-image, text-guided image editing, introducing new concepts, compositionality
- [Interpreting SD by cross attention](https://github.com/castorini/daam) 
- [Segmentation](https://github.com/JuliaWolleb/Diffusion-based-Segmentation) 
- [Segmentation Peekabo](https://arxiv.org/pdf/2211.13224.pdf) 
- [Object detection](https://arxiv.org/pdf/2211.09788.pdf](code)[https://github.com/ShoufaChen/DiffusionDet) 
- [SD2 Depth conditional](https://github.com/Stability-AI/stablediffusion#depth-conditional-stable-diffusion) 
- [Diffusers](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_depth2img.py) 
- [Pipeline examples](https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines#examples) 
- [Structured SD](https://arxiv.org/pdf/2212.05032.pdf)[github](https://github.com/weixi-feng/Structured-Diffusion-Guidance) 
- [Image editing Imagic](https://imagic-editing.github.io/) 
- [Null text inversion](https://arxiv.org/abs/2211.09794) 
- [Steering prompts for vector-like arithmetic](https://arxiv.org/pdf/2212.06013.pdf)  

#### 3D diffusion models
Either learning 3D info from 2D learned models or training for 3D from scratch.
- [PointE](https://arxiv.org/pdf/2212.08751.pdf) [code](https://github.com/openai/point-e)
- [RenderDiffusion - learned from monocular](https://github.com/Anciukevicius/RenderDiffusion)
- [Latent Point Diffusion LION](https://nv-tlabs.github.io/LION/)
- [Pose conditioned dif (novel view synthesis)](https://arxiv.org/pdf/2210.04628.pdf) 

## 3D Implicit models, Nerf, rendering
#### Nerf/SDF
- [SDFStudio](https://github.com/autonomousvision/sdfstudio)
- [NerfStudio](https://github.com/nerfstudio-project/nerfstudio)
- [Plenoxels spherical harmonics](https://alexyu.net/plenoxels/)
- [SDF based Nerf](https://arxiv.org/pdf/2210.08398.pdf)
- [Faster nerfs](https://chrischoy.github.io/research/nerfs/)
- [Stochastic Nerf](https://arxiv.org/pdf/2109.02123.pdf)
- [Probabilistic nerf](https://arxiv.org/pdf/2210.17415v1.pdf)
- [PNerf](https://arxiv.org/abs/2209.11677)
- [Conditional normalizing flow nerf](https://arxiv.org/pdf/2203.10192.pdf)
- [VolRecon (Signed ray distance function)](https://arxiv.org/abs/2212.08067)
- [Neural implicit queries (siggraph best paper)](https://nmwsharp.com/research/interval-implicits/) 

#### Compositional
- [Neural scene graph rendering](https://dl.acm.org/doi/abs/10.1145/3450626.3459848)
- [NSG for dynamic](https://openaccess.thecvf.com/content/CVPR2021/papers/Ost_Neural_Scene_Graphs_for_Dynamic_Scenes_CVPR_2021_paper.pdf)
- [Compositional Object light field](https://openreview.net/forum?id=fDgdqEuKX0&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR))
- [GIRAFFE](https://www.cvlibs.net/publications/Niemeyer2021CVPR.pdf) 

#### Others
- [Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions](https://arxiv.org/pdf/1805.09957.pdf)
- [Probabilistic scene modelling](https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Online_Learning_of_a_Probabilistic_and_Adaptive_Scene_Representation_CVPR_2021_paper.pdf)
- [Perfception : Nerf dataset for perception tasks](https://arxiv.org/pdf/2208.11537.pdf)
- [Neural feature fusion fields:](https://arxiv.org/pdf/2209.03494.pdf)   

## Multimodal vision language Learning
- [Open set recognition](https://www.wjscheirer.com/papers/wjs_tpami2013_openset.pdf)
- [Open world recognition (incrementally add novel classes)](https://arxiv.org/pdf/1412.5687.pdf)
- [OOD benchmarking](https://openreview.net/pdf?id=gT6j4_tskUt) 

#### Open vocabulary
- [Class agnostic object detection](https://arxiv.org/pdf/2111.11430.pdf)
- [image segmentation OpenSeg](https://arxiv.org/pdf/2112.12143.pdf)
- [Image seg ZSSeg](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890725.pdf)
- [Object detection OWL-ViT](https://arxiv.org/pdf/2205.06230.pdf)
- [object detection PrompDet](https://arxiv.org/pdf/2203.16513.pdf)
- [Another detection ovd](https://github.com/hanoonaR/object-centric-ovd)
- [3D object detection PrompDet](https://arxiv.org/pdf/2207.01987.pdf)
- [scene graph generation](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880055.pdf)
- [Attribute prediction  TAP](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850199.pdf)
- [CLIP seg](https://openaccess.thecvf.com/content/CVPR2022/papers/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.pdf)
- [Clip object det GLIP](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf)
- [CLIP for image captioning:](https://openaccess.thecvf.com/content/CVPR2022W/MULA/papers/Barraco_The_Unreasonable_Effectiveness_of_CLIP_Features_for_Image_Captioning_An_CVPRW_2022_paper.pdf)
- [Clip cap](https://github.com/rmokady/CLIP_prefix_caption) 

#### 3D language grounding
- [PointClip](https://arxiv.org/pdf/2211.11682.pdf)
- [Text to 3D pcd ShapeCrafter](https://t.co/VSqXignAV1)
- [OpenScene](https://arxiv.org/pdf/2211.15654.pdf)
- [Open vocab 3d](https://arxiv.org/pdf/2211.16312.pdf)
- [Semantic abstraction 3D](https://arxiv.org/abs/2207.11514)
- [PartSLIP](https://arxiv.org/pdf/2212.01558.pdf)
- [FrozenCLIP](https://arxiv.org/pdf/2212.04098.pdf)
- [ULIP: point cloud, image, text](https://github.com/salesforce/ULIP)
- [Towards OpenSet3D learning](https://arxiv.org/pdf/2207.11554.pdf) 

## Scene graphs
#### Limitations on capacity, counterfactual reasoning
Reflecting the most frequent nodes and edges according to long tail distribution, not really learning.
- [Probabilistic modeling](https://github.com/IIGROUP/PUM)
- [Probabilistic graph networks](https://grlearning.github.io/papers/135.pdf)
- [Unbiased learning](https://openaccess.thecvf.com/content_CVPR_2020/papers/Tang_Unbiased_Scene_Graph_Generation_From_Biased_Training_CVPR_2020_paper.pdf)
- [Weighted loss and metric for unbiased training, zero/few shot setting](https://arxiv.org/pdf/2005.08230.pdf) 

#### Usage in pure vision applications
Image manipulation, 3D scene graphs for retrieval, multimodal/concept scene graphs
- [SSG helps on semantic segmentation](https://proceedings.neurips.cc/paper/2018/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf)
- [3D Change captioning](https://dl.acm.org/doi/10.1145/3474085.3475712)
- [ZS with Commonsense SG from ConceptNet](https://arxiv.org/pdf/2107.05080.pdf)
- [ZS with Knowledge graph SG](https://ieeexplore.ieee.org/document/9859944)
- [SG with knowledge graph good comparison](https://2022.eswc-conferences.org/wp-content/uploads/2022/05/paper_72_Khan_et_al.pdf)
- [Open Set SG](https://ieeexplore.ieee.org/document/9690166) 

#### Usage in cross-modality, cross dataset 
Does it help with visual question answering, image captioning
- [Are SG good for image captioning? Are scene graphs good enough to improve Image Captioning?](https://arxiv.org/pdf/2009.12313.pdf)
- [Cross-modal SG](https://arxiv.org/abs/2106.15309)
- [SG with rich textual descriptions for better image retrieval](https://nlp.stanford.edu/pubs/schuster-krishna-chang-feifei-manning-vl15.pdf) 

## ML
#### Conformal Prediction
- [Conformal learning](https://www.youtube.com/watch?v=nql000Lu_iE)
- [For few shot](https://arxiv.org/pdf/2102.08898.pdf)
- [Conformal zero shot as ood](https://arxiv.org/pdf/2210.15805.pdf)
- [Conformal zero shot text classification](https://arxiv.org/pdf/2210.12619.pdf) 

#### Causality / counterfactuals
- [Connected papers](https://www.connectedpapers.com/main/22182a9b07777bbe2403ef061225402e3940117e/A-causal-view-of-compositional-zero%20shot-recognition/graph) 
- [Causal zero shot](https://arxiv.org/pdf/2006.14610.pdf) 
- [Counterfactual zs/osr](https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Counterfactual_Zero-Shot_and_Open-Set_Visual_Recognition_CVPR_2021_paper.pdf) 
- [Desiderata by Michael Jordan](https://arxiv.org/pdf/2109.03795.pdf) 
- [Diffusion visual counterfactuals](https://arxiv.org/pdf/2210.11841.pdf) 
- [CF for OOD](https://openreview.net/pdf?id=avgclFZ221l) 
- [CF for simulation testing](https://counterfactualsimulation.github.io/) 
- [CF commonsense reasoning dataset](https://arxiv.org/pdf/2207.03961.pdf) 

#### Object-centric Representation learning
- [Slot attention](https://arxiv.org/pdf/2006.15055.pdf) 
- [PARTS](https://github.com/wu375/parts-segmentation) 
- [ODIN](https://arxiv.org/pdf/2203.08777.pdf) 
- [SPAIR3D](https://arxiv.org/pdf/2106.05607.pdf) 
- [Complex valued AE](https://arxiv.org/pdf/2204.02075.pdf) 
- [Forward forward lowe](https://arxiv.org/pdf/1905.11786.pdf) 
- [FF hinton](https://www.cs.toronto.edu/~hinton/FFA13.pdf)
- [FF explained](https://mobile.twitter.com/martin_gorner/status/1599755684941557761) 
- [Hinton Brain and inverse graphics](https://www.reddit.com/r/MachineLearning/comments/3tmc1m/geoffrey_hinton_does_the_brain_do_inverse_graphics/) 
- [Deep Object Parsing](https://arxiv.org/pdf/2207.07110.pdf)

#### Others
- [Backward / forward compatible training](https://machinelearning.apple.com/research/forward-compatible-training) 
- [Transformers in-context learn sgd](https://arxiv.org/pdf/2212.07677.pdf) 
- [Relative representations - stitching embeddings](https://arxiv.org/abs/2209.15430) 
- [AI binding problem](https://arxiv.org/pdf/2012.05208.pdf) 
- [Transformers in 3D survey](https://arxiv.org/pdf/2208.04309.pdf) 
- [Transformer lecture](https://web.stanford.edu/class/cs25/) 
- [Open-set recognition: A good closed-set classifier is all you need?](https://arxiv.org/pdf/2110.06207.pdf) 

#### Neurips 2022 
- [Self supervised learning: theory and practice](https://neurips.cc/virtual/2022/workshop/49991) 
- [Symmetry and geometry:](https://neurips.cc/virtual/2022/workshop/49975) 
- [Info theoretic principles in cogs](https://neurips.cc/virtual/2022/workshop/49977) 
- [Data compression with ML](https://neurips.cc/virtual/2022/tutorial/55811) 
- [Foundation models](https://sites.google.com/view/neurips2022-frfm-turotial) 
- [Meta learning for few shot learning](https://neurips.cc/virtual/2022/tutorial/55814) 


## Summarizing the year 

One step closer to general purpose AI, or Artifical General Intelligence, we can already make some predictions for what is coming in the next years, like a possible new version of ChatGPT, many papers on diffusion models with all sorts of computer vision tasks. We might see Nerf getting implemented in specialized hardware, maybe in phones. Really interesting usecases will be on compression, like sharing a 3d model across devices for very low costs. Further, I wish to see Perceiver IO or maybe a better general-purpose artificial consumer to replace ViTs and convs, like "one model to rule them all", we just introduce the modality as a one-hot vector, the task as another one-hot vector and representations to all different modalities will be shared. This would be far from optimal domain specific algorithms but the best consumer of data would win(?). Anything we work on makes sense, but big labs in long-run could have higher chances to win on this race, as they have more resources and networks of talent. Isn't it always historically a bit like that? Militaries got replaced by FAANG, creating the era of frozen war :P anyways, enough with overthinking, it is always interesting to put yourself as a witness and see how things progress in the world. In 2022, drastic climate changes floods and fires, war in Ukraine, wordle game, Elon Musk buying twitter, World Cup. I think humans and society is oftentimes very unpredictable, but the only steady and expected thing is the progress in AI. I remember the first year of my bachelors, 2013, asking my professor "I've heard this thing about deep learning, what the heck is that" and my professor explaining me in very high-level concept, showing his desk "You see this desk here, but how do you know it is there? it is actually a probability." 
Now, let's apply counterfactual intervention in reality by touching the desk and hopefully increasing its probability :)      

